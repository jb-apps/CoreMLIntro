{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "55200efb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting PyTorch Frontend ==> MIL Ops:  99%|██████████████████████████████████████████████████▋| 187/188 [00:00<00:00, 12480.86 ops/s]\n",
      "Running MIL frontend_pytorch pipeline: 100%|███████████████████████████████████████████████████████| 5/5 [00:00<00:00, 2644.25 passes/s]\n",
      "Running MIL default pipeline: 100%|██████████████████████████████████████████████████████████████| 65/65 [00:00<00:00, 1212.64 passes/s]\n",
      "Running MIL backend_neuralnetwork pipeline: 100%|██████████████████████████████████████████████████| 9/9 [00:00<00:00, 3846.42 passes/s]\n",
      "Translating MIL ==> NeuralNetwork Ops: 100%|███████████████████████████████████████████████████████| 184/184 [00:00<00:00, 575.69 ops/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantizing using linear quantization\n",
      "Quantizing layer input.1 of type convolution\n",
      "Quantizing layer input.5 of type convolution\n",
      "Quantizing layer input.9 of type convolution\n",
      "Quantizing layer input.13 of type convolution\n",
      "Quantizing layer input.17 of type convolution\n",
      "Quantizing layer input.21 of type convolution\n",
      "Quantizing layer input.25 of type convolution\n",
      "Quantizing layer input.29 of type convolution\n",
      "Quantizing layer input.33 of type convolution\n",
      "Quantizing layer input.37 of type convolution\n",
      "Quantizing layer input.41 of type convolution\n",
      "Quantizing layer input.45 of type convolution\n",
      "Quantizing layer input.49 of type convolution\n",
      "Quantizing layer input.53 of type convolution\n",
      "Quantizing layer input.57 of type convolution\n",
      "Quantizing layer input.61 of type convolution\n",
      "Quantizing layer input.65 of type convolution\n",
      "Quantizing layer input of type convolution\n",
      "Finish quantization\n"
     ]
    }
   ],
   "source": [
    "import coremltools as ct\n",
    "from coremltools.models.neural_network import NeuralNetworkBuilder\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from basicsr.archs.srvgg_arch import SRVGGNetCompact\n",
    "\n",
    "#'''\n",
    "weights_path = 'weights/realesr-animevideov3.pth'\n",
    "input_trace = (1, 3, 512, 512)\n",
    "filename = 'AnimeTurbo'\n",
    "num_conv = 16 #Anime\n",
    "\n",
    "'''\n",
    "\n",
    "weights_path = 'weights/realesr-general-x4v3.pth'\n",
    "input_trace = (1, 3, 720, 1280)\n",
    "filename = 'Picture1920x1920'\n",
    "num_conv = 32 #Picture\n",
    "#'''\n",
    "\n",
    "# Load the original model\n",
    "model = SRVGGNetCompact(num_in_ch=3, num_out_ch=3, num_feat=64, num_conv=num_conv, upscale=4, act_type='prelu')\n",
    "\n",
    "loadnet = torch.load(weights_path, map_location=torch.device('cpu'))\n",
    "model.load_state_dict(loadnet['params'], strict=True)\n",
    "model.train(False)\n",
    "model.cpu().eval()\n",
    "\n",
    "# Convert to CoreML 512 x 512\n",
    "\n",
    "example_input = torch.rand(input_trace)\n",
    "\n",
    "# Trace the model\n",
    "traced_model = torch.jit.trace(model, example_input)\n",
    "\n",
    "input_shape = ct.Shape(shape=(1,\n",
    "                              3,\n",
    "                              ct.RangeDim(lower_bound=64, upper_bound=1536, default=384),\n",
    "                              ct.RangeDim(lower_bound=64, upper_bound=1536, default=384)\n",
    "                             )\n",
    "                      )\n",
    "\n",
    "input_image = ct.ImageType(shape=input_shape, color_layout=ct.colorlayout.RGB, scale=1/255.0)\n",
    "\n",
    "# Define input / output types\n",
    "mlmodel = ct.convert(\n",
    "    traced_model,\n",
    "    inputs=[input_image],\n",
    "    convert_to=\"neuralnetwork\"\n",
    ")\n",
    "\n",
    "mlmodel.save(f\"{filename}.mlmodel\")\n",
    "\n",
    "############## FIX OUTPUT ######################\n",
    "\n",
    "# Load the Core ML model\n",
    "spec = ct.utils.load_spec(f\"{filename}.mlmodel\")\n",
    "\n",
    "# Create a builder from the existing spec\n",
    "builder = NeuralNetworkBuilder(spec=spec)\n",
    "\n",
    "# Get the name of the last layer in the model\n",
    "last_layer = builder.spec.neuralNetwork.layers[-1].output[0]\n",
    "\n",
    "# Add an ActivationLinear layer to scale the output\n",
    "builder.add_activation(name=\"scaled\",\n",
    "                       non_linearity=\"LINEAR\",\n",
    "                       input_name=last_layer,\n",
    "                       output_name=\"scaled\",\n",
    "                       params=[255.0, 0.0])  # Params for the LINEAR activation function (alpha, beta)\n",
    "\n",
    "# Add a Squeeze layer after the scaling layer\n",
    "\n",
    "builder.add_squeeze(name=\"enhanced\",\n",
    "                    input_name=\"scaled\",\n",
    "                    output_name=\"enhanced\",\n",
    "                    axes=[0])\n",
    "\n",
    "# Update the output of the model to be the output of the squeeze layer\n",
    "builder.spec.description.output[0].name = 'enhanced'\n",
    "\n",
    "# Save the modified model\n",
    "ct.utils.save_spec(builder.spec, f\"{filename}.mlmodel\")\n",
    "\n",
    "##################### Quantized 16 bits #######################\n",
    "\n",
    "import coremltools as ct\n",
    "from coremltools.models.neural_network import quantization_utils\n",
    "\n",
    "# load full precision model\n",
    "model_fp32 = ct.models.MLModel(f\"{filename}.mlmodel\")\n",
    "\n",
    "model_fp16 = quantization_utils.quantize_weights(model_fp32, nbits=16)\n",
    "\n",
    "model_fp16.save(f\"{filename}.mlmodel\")\n",
    "print(\"Finish quantization\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fc14be65",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting PyTorch Frontend ==> MIL Ops: 100%|███████████████████████████████████████████████████▉| 814/815 [00:00<00:00, 8393.99 ops/s]\n",
      "Running MIL frontend_pytorch pipeline: 100%|████████████████████████████████████████████████████████| 5/5 [00:00<00:00, 359.25 passes/s]\n",
      "Running MIL default pipeline: 100%|███████████████████████████████████████████████████████████████| 65/65 [00:00<00:00, 200.79 passes/s]\n",
      "Running MIL backend_neuralnetwork pipeline: 100%|███████████████████████████████████████████████████| 9/9 [00:00<00:00, 650.38 passes/s]\n",
      "Translating MIL ==> NeuralNetwork Ops: 100%|███████████████████████████████████████████████████████| 945/945 [00:02<00:00, 396.43 ops/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantizing using linear quantization\n",
      "Quantizing layer input.1 of type convolution\n",
      "Quantizing layer input.3 of type convolution\n",
      "Quantizing layer input.7 of type convolution\n",
      "Quantizing layer input.11 of type convolution\n",
      "Quantizing layer input.15 of type convolution\n",
      "Quantizing layer 87 of type convolution\n",
      "Quantizing layer input.21 of type convolution\n",
      "Quantizing layer input.25 of type convolution\n",
      "Quantizing layer input.29 of type convolution\n",
      "Quantizing layer input.33 of type convolution\n",
      "Quantizing layer 142 of type convolution\n",
      "Quantizing layer input.39 of type convolution\n",
      "Quantizing layer input.43 of type convolution\n",
      "Quantizing layer input.47 of type convolution\n",
      "Quantizing layer input.51 of type convolution\n",
      "Quantizing layer 197 of type convolution\n",
      "Quantizing layer input.57 of type convolution\n",
      "Quantizing layer input.61 of type convolution\n",
      "Quantizing layer input.65 of type convolution\n",
      "Quantizing layer input.69 of type convolution\n",
      "Quantizing layer 258 of type convolution\n",
      "Quantizing layer input.75 of type convolution\n",
      "Quantizing layer input.79 of type convolution\n",
      "Quantizing layer input.83 of type convolution\n",
      "Quantizing layer input.87 of type convolution\n",
      "Quantizing layer 313 of type convolution\n",
      "Quantizing layer input.93 of type convolution\n",
      "Quantizing layer input.97 of type convolution\n",
      "Quantizing layer input.101 of type convolution\n",
      "Quantizing layer input.105 of type convolution\n",
      "Quantizing layer 368 of type convolution\n",
      "Quantizing layer input.111 of type convolution\n",
      "Quantizing layer input.115 of type convolution\n",
      "Quantizing layer input.119 of type convolution\n",
      "Quantizing layer input.123 of type convolution\n",
      "Quantizing layer 429 of type convolution\n",
      "Quantizing layer input.129 of type convolution\n",
      "Quantizing layer input.133 of type convolution\n",
      "Quantizing layer input.137 of type convolution\n",
      "Quantizing layer input.141 of type convolution\n",
      "Quantizing layer 484 of type convolution\n",
      "Quantizing layer input.147 of type convolution\n",
      "Quantizing layer input.151 of type convolution\n",
      "Quantizing layer input.155 of type convolution\n",
      "Quantizing layer input.159 of type convolution\n",
      "Quantizing layer 539 of type convolution\n",
      "Quantizing layer input.165 of type convolution\n",
      "Quantizing layer input.169 of type convolution\n",
      "Quantizing layer input.173 of type convolution\n",
      "Quantizing layer input.177 of type convolution\n",
      "Quantizing layer 600 of type convolution\n",
      "Quantizing layer input.183 of type convolution\n",
      "Quantizing layer input.187 of type convolution\n",
      "Quantizing layer input.191 of type convolution\n",
      "Quantizing layer input.195 of type convolution\n",
      "Quantizing layer 655 of type convolution\n",
      "Quantizing layer input.201 of type convolution\n",
      "Quantizing layer input.205 of type convolution\n",
      "Quantizing layer input.209 of type convolution\n",
      "Quantizing layer input.213 of type convolution\n",
      "Quantizing layer 710 of type convolution\n",
      "Quantizing layer input.219 of type convolution\n",
      "Quantizing layer input.223 of type convolution\n",
      "Quantizing layer input.227 of type convolution\n",
      "Quantizing layer input.231 of type convolution\n",
      "Quantizing layer 771 of type convolution\n",
      "Quantizing layer input.237 of type convolution\n",
      "Quantizing layer input.241 of type convolution\n",
      "Quantizing layer input.245 of type convolution\n",
      "Quantizing layer input.249 of type convolution\n",
      "Quantizing layer 826 of type convolution\n",
      "Quantizing layer input.255 of type convolution\n",
      "Quantizing layer input.259 of type convolution\n",
      "Quantizing layer input.263 of type convolution\n",
      "Quantizing layer input.267 of type convolution\n",
      "Quantizing layer 881 of type convolution\n",
      "Quantizing layer input.273 of type convolution\n",
      "Quantizing layer input.277 of type convolution\n",
      "Quantizing layer input.281 of type convolution\n",
      "Quantizing layer input.285 of type convolution\n",
      "Quantizing layer 942 of type convolution\n",
      "Quantizing layer input.291 of type convolution\n",
      "Quantizing layer input.295 of type convolution\n",
      "Quantizing layer input.299 of type convolution\n",
      "Quantizing layer input.303 of type convolution\n",
      "Quantizing layer 997 of type convolution\n",
      "Quantizing layer input.309 of type convolution\n",
      "Quantizing layer input.313 of type convolution\n",
      "Quantizing layer input.317 of type convolution\n",
      "Quantizing layer input.321 of type convolution\n",
      "Quantizing layer 1052 of type convolution\n",
      "Quantizing layer body_feat of type convolution\n",
      "Quantizing layer input.331 of type convolution\n",
      "Quantizing layer input.337 of type convolution\n",
      "Quantizing layer input.341 of type convolution\n",
      "Quantizing layer var_1129 of type convolution\n",
      "Finish quantization\n"
     ]
    }
   ],
   "source": [
    "import coremltools as ct\n",
    "from coremltools.models.neural_network import NeuralNetworkBuilder\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from basicsr.archs.rrdbnet_arch import RRDBNet\n",
    "\n",
    "#'''\n",
    "weights_path = 'weights/RealESRGAN_x4plus_anime_6B.pth'\n",
    "input_trace = (1, 3, 512, 512)\n",
    "filename = 'Anime'\n",
    "\n",
    "# Load the original model\n",
    "model = RRDBNet(num_in_ch=3, num_out_ch=3, num_feat=64, num_block=6, num_grow_ch=32, scale=4)\n",
    "\n",
    "loadnet = torch.load(weights_path, map_location=torch.device('cpu'))\n",
    "model.load_state_dict(loadnet['params_ema'], strict=True)\n",
    "'''\n",
    "\n",
    "weights_path = 'weights/realesr-general-x4v3.pth'\n",
    "input_trace = (1, 3, 720, 1280)\n",
    "filename = 'Picture1920x1920'\n",
    "num_conv = 32 #Picture\n",
    "#'''\n",
    "\n",
    "model.train(False)\n",
    "model.cpu().eval()\n",
    "\n",
    "# Convert to CoreML 512 x 512\n",
    "\n",
    "example_input = torch.rand(input_trace)\n",
    "\n",
    "# Trace the model\n",
    "traced_model = torch.jit.trace(model, example_input)\n",
    "\n",
    "input_shape = ct.Shape(shape=(1,\n",
    "                              3,\n",
    "                              ct.RangeDim(lower_bound=64, upper_bound=1536, default=384),\n",
    "                              ct.RangeDim(lower_bound=64, upper_bound=1536, default=384)\n",
    "                             )\n",
    "                      )\n",
    "\n",
    "input_image = ct.ImageType(shape=input_shape, color_layout=ct.colorlayout.RGB, scale=1/255.0)\n",
    "\n",
    "# Define input / output types\n",
    "mlmodel = ct.convert(\n",
    "    traced_model,\n",
    "    inputs=[input_image],\n",
    "    convert_to=\"neuralnetwork\"\n",
    ")\n",
    "\n",
    "mlmodel.save(f\"{filename}.mlmodel\")\n",
    "\n",
    "############## FIX OUTPUT ######################\n",
    "\n",
    "# Load the Core ML model\n",
    "spec = ct.utils.load_spec(f\"{filename}.mlmodel\")\n",
    "\n",
    "# Create a builder from the existing spec\n",
    "builder = NeuralNetworkBuilder(spec=spec)\n",
    "\n",
    "# Get the name of the last layer in the model\n",
    "last_layer = builder.spec.neuralNetwork.layers[-1].output[0]\n",
    "\n",
    "# Add an ActivationLinear layer to scale the output\n",
    "builder.add_activation(name=\"scaled\",\n",
    "                       non_linearity=\"LINEAR\",\n",
    "                       input_name=last_layer,\n",
    "                       output_name=\"scaled\",\n",
    "                       params=[255.0, 0.0])  # Params for the LINEAR activation function (alpha, beta)\n",
    "\n",
    "# Add a Squeeze layer after the scaling layer\n",
    "\n",
    "builder.add_squeeze(name=\"enhanced\",\n",
    "                    input_name=\"scaled\",\n",
    "                    output_name=\"enhanced\",\n",
    "                    axes=[0])\n",
    "\n",
    "# Update the output of the model to be the output of the squeeze layer\n",
    "builder.spec.description.output[0].name = 'enhanced'\n",
    "\n",
    "# Save the modified model\n",
    "ct.utils.save_spec(builder.spec, f\"{filename}.mlmodel\")\n",
    "\n",
    "##################### Quantized 16 bits #######################\n",
    "\n",
    "import coremltools as ct\n",
    "from coremltools.models.neural_network import quantization_utils\n",
    "\n",
    "# load full precision model\n",
    "model_fp32 = ct.models.MLModel(f\"{filename}.mlmodel\")\n",
    "\n",
    "model_fp16 = quantization_utils.quantize_weights(model_fp32, nbits=16)\n",
    "\n",
    "model_fp16.save(f\"{filename}.mlmodel\")\n",
    "print(\"Finish quantization\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
